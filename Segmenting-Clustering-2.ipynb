#!/usr/bin/env python
# coding: utf-8

# # Segmenting and Clustering Neighborhoods in Toronto

# ### Part 1

# ##### Installing LXML to be able to read html page:

# In[1]:


get_ipython().system('pip install lxml')


# ##### Importing required libraries:

# In[2]:


import numpy as np # library to handle data in a vectorized manner
import html5lib
import pandas as pd # library for data analsysis
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)
            
import json # library to handle JSON files

get_ipython().system("conda install -c conda-forge geopy --yes # uncomment this line if you haven't completed the Foursquare API lab")
from geopy.geocoders import Nominatim # convert an address into latitude and longitude values

import requests # library to handle requests
from pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe

# Matplotlib and associated plotting modules
import matplotlib.cm as cm
import matplotlib.colors as colors

# import k-means from clustering stage
from sklearn.cluster import KMeans

get_ipython().system("conda install -c conda-forge folium=0.5.0 --yes # uncomment this line if you haven't completed the Foursquare API lab")
import folium # map rendering library

print('Libraries imported.')


# ##### Reading HTML into 'data' object:

# In[3]:


data = pd.read_html ('https://en.wikipedia.org/w/index.php?title=List_of_postal_codes_of_Canada:_M&direction=prev&oldid=926287641')
#data


# ##### Reading only 1st table of the HTML page into dataframe:

# In[4]:


df = data[0]
df.head()


# ##### Removing the rows with a NAN value in 'Borough' column, also sorted the Dataframe by the column 'Postcode':

# In[5]:


df1 = df[df.Borough != 'Not assigned'].reset_index(drop=True)
df1.sort_values(by='Postcode',ascending=True,inplace=True)
df1.reset_index(drop=True).head(7)


# ##### Identifying the NAN values in the Neighbourhood column.<br>Replacing the NAN values by the corresponding Borough value.

# In[6]:


i=0
for name in list (df1.Neighbourhood):
    if name == 'Not assigned':
        df1.Neighbourhood[i] = df1.Borough[i]
    i+=1
df1.head(7)


# ##### Shrinked the table with the use of Groupby on columns Postcode & Borough. Used count() method to obtain the number of Neighbourhoods in each group.

# In[7]:


dfgroup = df1.groupby(['Postcode','Borough']).count()
dfgroup.reset_index(inplace=True)
dfgroup.head()


# ##### As required, Neighbourhoods with the same Postcode are brought into 1 cell seperated by comma using join function:
# Here, we have used 2 dataframes, df1 & dfgroup. <br>***df1***: It has all the rows obtained from HTML page after removing 'NAN' Boroughs.<br>***dfgroup***: It has unique values of Postcodes
# <br><br>Hence, referring to the Postcode values of dfgroup dataframe, we are traversing throught the df1 dataframe to obtain all the corresponding Neighbourhood values for that particular Postcode. The obtained Neighbourhood values are appended into the list 'lst'. Once, the traversing through the df1 dataframe is complete, the list 'lst' is converted into string seperated by comma and feeded into the corresponding row of Neighbourhood column of the dfgroup dataframe.
# <br>Hence, finally the desired dataframe is obtained.

# In[8]:


j=0
for pcgp in list (dfgroup.Postcode):
    lst = []
    i=0
    for pc1 in list(df1.Postcode):
        if pcgp == pc1:
            lst.append(df1.Neighbourhood[i])
        i+=1
    lst = list (set(lst))
    dfgroup.Neighbourhood[j] = ','.join([str(ngh) for ngh in lst])
    j+=1
    
print ('Loop completed')   
dfgroup


# ##### Shape of dfgroup dataframe:

# In[9]:


dfgroup.shape


# ### Part 2

# ##### Created a new DF named 'dfll' which is a copy of the above dataframe 'dfgroup'. <br>Also, introduced 2 new columns: 'Latitude' and 'Longitude' with a default value of 0.0:

# In[10]:


dfll = dfgroup
dfll.insert(3,'Latitude',0.0,True)
dfll.insert(4,'Longitude',0.0,True)
dfll.head()


# ##### Introduced an 'Address' column that will be passed to the geocoder:

# In[11]:


dfll['Address'] = dfll['Postcode']+','+'Toronto'+','+'Ontario'
dfll.head()


# ##### Importing rate.limiter to introduce delay between the calls to geocoder:

# In[12]:


from geopy.extra.rate_limiter import RateLimiter


# ##### Calling the API to obtain the required location details:

# In[13]:


geolocator = Nominatim(user_agent='abc')
geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)
dfll['location'] = dfll['Address'].apply(geocode)
dfll['point'] = dfll['location'].apply(lambda loc: tuple(loc.point) if loc else None)
dfll[['latitude', 'longitude', 'altitude']] = pd.DataFrame(dfll['point'].tolist(), index=dfll.index)  

dfll.drop(['Latitude','Longitude','point','altitude'],axis=1,inplace=True)


# ##### Below are the obtained values in df format.

# In[14]:


dfll.head(10)


# ##### As the values obtained from geocoder do not match with values in the csv file, below is the data read from the csv file and entered in the dataframe 'dfll':

# In[15]:


import csv
file = 'Geospatial_Coordinates.csv'


# In[16]:


lstgc = []
with open(file,'r') as rfile:
    var = csv.reader(rfile)
    for row in var:
        lstgc.append(row)    
        
lstgc = lstgc[1:]
print (lstgc)


# In[17]:


i = 0
for item in lstgc:
    if item[0] == dfll.Postcode[i]:
        dfll.latitude[i] = item[1]
        dfll.longitude[i] = item[2]
    i+=1
dfll.drop(['Address','location'],axis=1,inplace=True)
dfll.head(10)


# In[ ]:





# In[ ]:




